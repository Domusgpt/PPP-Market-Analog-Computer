{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Domusgpt/PPP-Market-Analog-Computer/blob/claude%2Fanalyze-project-continuation-ZKCoW/domain_diverse_training_ipynb_(1)_txt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7MJknkbClHg"
      },
      "source": [
        "# HEMOC Domain-Diverse Training (Phase C)\n",
        "\n",
        "**Goal**: Fix cross-domain transfer failure by training on ALL domains simultaneously.\n",
        "\n",
        "**Background**: Music-trained CNN achieves 0.916 correlation on music data but FAILS on market/sensor data (correlation -0.027). This experiment trains on mixed domains (25% music + 25% market + 25% sensor + 25% random) to produce a domain-agnostic decoder.\n",
        "\n",
        "**Important**: This uses `HybridEncoder` from `demos/dual_decoder.py` — NOT the old `OpticalKirigamiEncoder` from `main.py`.\n",
        "\n",
        "**Requirements**: GPU runtime (Runtime > Change runtime type > T4 GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRSH7Al3ClHk"
      },
      "source": [
        "## 1. Setup: Clone HEMOC repo and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrr9ZOxIClHl",
        "outputId": "7e9b3f18-48eb-4b93-8ecf-0fb22e3bef95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HEMOC-Stain-Glass-Flower'...\n",
            "remote: Enumerating objects: 7037, done.\u001b[K\n",
            "remote: Counting objects: 100% (319/319), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 7037 (delta 273), reused 231 (delta 225), pack-reused 6718 (from 3)\u001b[K\n",
            "Receiving objects: 100% (7037/7037), 77.80 MiB | 16.84 MiB/s, done.\n",
            "Resolving deltas: 100% (1776/1776), done.\n",
            "* \u001b[32mjules-7629987832936421389-695948c7\u001b[m\n",
            "---\n",
            "demos/domain_diverse_training.py  demos/dual_decoder.py\n"
          ]
        }
      ],
      "source": [
        "# Clone the HEMOC repo — use the jules branch which has experiments 1-24 + all results\n",
        "!git clone --branch jules-7629987832936421389-695948c7 \\\n",
        "    https://github.com/Domusgpt/HEMOC-Stain-Glass-Flower.git\n",
        "\n",
        "# Verify we're on the right branch\n",
        "!cd HEMOC-Stain-Glass-Flower && git branch && echo \"---\" && ls demos/dual_decoder.py demos/domain_diverse_training.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiZ88QOxClHn",
        "outputId": "291183d6-9c5b-4e18-ad58-166ee5036641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.9.0+cu128\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-994692451.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GPU: {torch.cuda.get_device_name(0)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WARNING: No GPU detected! Go to Runtime > Change runtime type > T4 GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > T4 GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgRMvfb4ClHn"
      },
      "source": [
        "## 2. Verify the Working Pipeline (HybridEncoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HHk-IMjClHo"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add the demos directory to path\n",
        "sys.path.insert(0, 'HEMOC-Stain-Glass-Flower/demos')\n",
        "\n",
        "from dual_decoder import HybridEncoder\n",
        "\n",
        "# Create encoder\n",
        "encoder = HybridEncoder(size=64)\n",
        "print(\"HybridEncoder initialized (64x64)\")\n",
        "print(f\"  Input: 6 angles in [-pi, pi]\")\n",
        "print(f\"  Output: (3, 64, 64) RGB pattern\")\n",
        "print(f\"  Angles 0-2: Linear path (phase, rotation, tilt)\")\n",
        "print(f\"  Angles 3-5: Hypercube path (non-linear mixing)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMV6ZiyuClHo"
      },
      "outputs": [],
      "source": [
        "# Quick sanity check: generate some patterns and visualize\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "np.random.seed(42)\n",
        "for i in range(8):\n",
        "    angles = np.random.uniform(-np.pi, np.pi, 6).astype(np.float32)\n",
        "    pattern = encoder.generate(angles)\n",
        "    ax = axes[i // 4, i % 4]\n",
        "    # pattern is (3, H, W), transpose to (H, W, 3) for display\n",
        "    ax.imshow(np.transpose(pattern, (1, 2, 0)))\n",
        "    ax.set_title(f'Sample {i+1}', fontsize=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('HybridEncoder: Random Angle Samples', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Verify determinism\n",
        "test_angles = np.array([0.5, -0.3, 1.2, -0.8, 0.1, -1.5], dtype=np.float32)\n",
        "p1 = encoder.generate(test_angles)\n",
        "p2 = encoder.generate(test_angles)\n",
        "print(f\"Determinism check: max diff = {np.max(np.abs(p1 - p2)):.2e} (should be 0)\")\n",
        "print(f\"Pattern shape: {p1.shape} (should be (3, 64, 64))\")\n",
        "print(f\"Pattern range: [{p1.min():.3f}, {p1.max():.3f}] (should be [0, 1])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_FmCJJGClHp"
      },
      "source": [
        "## 3. Run Domain-Diverse Training\n",
        "\n",
        "This runs the full experiment:\n",
        "- **Experiment A**: Train CNN on ALL 4 domains (25% each: music/market/sensor/random)\n",
        "- **Experiment B**: Train CNN on music-only (same total data, for comparison)\n",
        "- **Evaluation**: Test both models on held-out data from each domain separately\n",
        "\n",
        "On GPU: ~60K training samples, 80 epochs (~15-30 min)\n",
        "On CPU: ~16K training samples, 50 epochs (~60+ min, not recommended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wkvE6F4ClHp"
      },
      "outputs": [],
      "source": [
        "# Change to the HEMOC repo directory so imports work\n",
        "os.chdir('HEMOC-Stain-Glass-Flower')\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify key files exist\n",
        "for f in ['demos/dual_decoder.py', 'demos/domain_diverse_training.py', 'demos/option_e_scaled_cnn.py']:\n",
        "    exists = os.path.exists(f)\n",
        "    print(f\"  {f}: {'OK' if exists else 'MISSING!'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCJj2cLEClHq"
      },
      "outputs": [],
      "source": [
        "# Run the domain-diverse training experiment\n",
        "# This is the main experiment — takes 15-30 min on GPU, 60+ min on CPU\n",
        "#\n",
        "# It runs as a script (not import) so __file__-based imports work correctly\n",
        "!cd demos && python domain_diverse_training.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Co_RMk7ClHq"
      },
      "source": [
        "## 4. Analyze Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mVAddJuClHq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load saved results\n",
        "with open('results/domain_diverse_results.json', 'r') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "print(f\"Experiment: {results['experiment']}\")\n",
        "print(f\"Timestamp: {results['timestamp']}\")\n",
        "print(f\"Device: {results['device']}\")\n",
        "print(f\"Total training samples: {results['config']['total_train']:,}\")\n",
        "print(f\"\\nVerdict: {results['verdict']}\")\n",
        "print(f\"\\nCross-domain improvement: {results['comparison']['improvement']:+.4f}\")\n",
        "print(f\"In-domain cost: {results['comparison']['in_domain_cost']:+.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_lb_BEdClHr"
      },
      "outputs": [],
      "source": [
        "# Visualize: Diverse vs Music-Only across domains\n",
        "domains = ['music', 'market', 'sensor', 'random']\n",
        "\n",
        "diverse_corrs = [results['diverse_model'][d]['avg_corr'] for d in domains]\n",
        "music_corrs = [results['music_model'][d]['avg_corr'] for d in domains]\n",
        "\n",
        "x = np.arange(len(domains))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars1 = ax.bar(x - width/2, diverse_corrs, width, label='Diverse Model', color='steelblue')\n",
        "bars2 = ax.bar(x + width/2, music_corrs, width, label='Music-Only Model', color='coral')\n",
        "\n",
        "ax.set_xlabel('Test Domain')\n",
        "ax.set_ylabel('Average Correlation')\n",
        "ax.set_title('Domain-Diverse vs Music-Only: Cross-Domain Transfer')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(domains)\n",
        "ax.legend()\n",
        "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Pass threshold')\n",
        "ax.set_ylim(-0.2, 1.0)\n",
        "\n",
        "# Add value labels\n",
        "for bar in bars1:\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
        "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
        "for bar in bars2:\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.02,\n",
        "            f'{bar.get_height():.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kptg4yWyClHr"
      },
      "outputs": [],
      "source": [
        "# Per-angle heatmap: Diverse model across domains\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "for idx, (model_key, title) in enumerate([('diverse_model', 'Diverse Model'), ('music_model', 'Music-Only Model')]):\n",
        "    data = np.array([results[model_key][d]['per_angle_corr'] for d in domains])\n",
        "    im = axes[idx].imshow(data, cmap='RdYlGn', vmin=-0.5, vmax=1.0, aspect='auto')\n",
        "    axes[idx].set_xticks(range(6))\n",
        "    axes[idx].set_xticklabels([f'a{i}\\n({\"lin\" if i < 3 else \"hyp\"})' for i in range(6)])\n",
        "    axes[idx].set_yticks(range(4))\n",
        "    axes[idx].set_yticklabels(domains)\n",
        "    axes[idx].set_title(title)\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(4):\n",
        "        for j in range(6):\n",
        "            color = 'white' if data[i, j] < 0.3 else 'black'\n",
        "            axes[idx].text(j, i, f'{data[i,j]:.2f}', ha='center', va='center',\n",
        "                          color=color, fontsize=9)\n",
        "\n",
        "plt.colorbar(im, ax=axes, label='Correlation')\n",
        "plt.suptitle('Per-Angle Correlation by Domain', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SIMbmODClHr"
      },
      "outputs": [],
      "source": [
        "# Summary table\n",
        "print(\"=\" * 70)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n{'Model':<20} {'Music':<10} {'Market':<10} {'Sensor':<10} {'Random':<10} {'Cross-Avg':<10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for model_key, label in [('diverse_model', 'Diverse'), ('music_model', 'Music-Only')]:\n",
        "    corrs = [results[model_key][d]['avg_corr'] for d in domains]\n",
        "    cross_avg = np.mean(corrs[1:])  # market + sensor + random\n",
        "    print(f\"{label:<20} {corrs[0]:<10.4f} {corrs[1]:<10.4f} {corrs[2]:<10.4f} {corrs[3]:<10.4f} {cross_avg:<10.4f}\")\n",
        "\n",
        "print(f\"\\nPrevious results:\")\n",
        "print(f\"  Music pipeline (Exp 13): 0.916 avg corr (music only)\")\n",
        "print(f\"  Cross-domain (Exp 14-15): -0.027 to 0.077 (FAIL)\")\n",
        "print(f\"\\nVerdict: {results['verdict']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFlnzScIClHr"
      },
      "source": [
        "## 5. Save Results for PPP Integration\n",
        "\n",
        "Download the results JSON for the evidence table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-IfwnCOClHs"
      },
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "files.download('results/domain_diverse_results.json')\n",
        "print(\"Results downloaded. Add to PPP repo as evidence artifact.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}